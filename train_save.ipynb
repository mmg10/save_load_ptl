{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fde440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress import ProgressBar\n",
    "\n",
    "\n",
    "import tableprint as tp\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd9a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dvc\n",
    "!dvc get https://github.com/iterative/dataset-registry tutorials/versioning/data.zip\n",
    "!unzip -q data.zip\n",
    "!rm -f data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383fde13",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './data/train'\n",
    "TEST_PATH = './data/validation'\n",
    "\n",
    "img_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_data = datasets.ImageFolder(TRAIN_PATH, transform=img_transforms)\n",
    "val_data = datasets.ImageFolder(TEST_PATH, transform=img_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df9feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size,  num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "288efae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # conv layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=18, kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=18, out_channels=3, kernel_size=3, stride=2)\n",
    "        \n",
    "        # dense layers\n",
    "        self.fc1 = nn.Linear(2187 , 1024)\n",
    "        self.fc2 = nn.Linear(1024 , 2)\n",
    "            \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X)) # here, RELU is being treated as a function rather than a layer/module\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.relu(self.conv3(X))\n",
    "        X = X.view(-1, 2187)\n",
    "        X = F.dropout(X, p=0.2)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.dropout(X, p=0.2)\n",
    "        X = self.fc2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ef88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49714516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = model\n",
    "        self.avg_train_loss = 0.\n",
    "        self.avg_valid_loss = 0.\n",
    "        self.table_context = None\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.start_time = 0\n",
    "        self.end_time = 0\n",
    "        self.epoch_mins = 0\n",
    "        self.epoch_secs = 0\n",
    "        self.table_context = None\n",
    "        self.train_accm = torchmetrics.Accuracy()\n",
    "        self.valid_accm = torchmetrics.Accuracy()\n",
    "        self.train_acc = 0.\n",
    "        self.valid_acc = 0.\n",
    "\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=0.0005)\n",
    "        return optim\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, target = batch\n",
    "        output = self.model(data)\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        acc_train = self.train_accm(predictions, target)\n",
    "        loss = self.loss_fn(output, target)\n",
    "        return {\"loss\": loss, \"p\": predictions, \"y\": target}\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, target = batch\n",
    "        output = self.model(data)\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        acc_valid = self.valid_accm(predictions, target)\n",
    "        loss_valid = self.loss_fn(output, target)\n",
    "        return {\"loss\": loss_valid, \"p\": predictions, \"y\": target}\n",
    "\n",
    "\n",
    "    def on_train_epoch_start(self) :\n",
    "        self.start_time = time.time()\n",
    "\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        if self.trainer.sanity_checking:\n",
    "          return\n",
    "        \n",
    "        self.avg_valid_loss = torch.stack([x['loss'] for x in outputs]).mean().item()\n",
    "        self.valid_acc = (self.valid_accm.compute() * 100).item()\n",
    "        self.valid_accm.reset()\n",
    "        self.log(\"epoch_num\", int(self.current_epoch+1), on_step=False, on_epoch=True, prog_bar=False, logger=False)\n",
    "        self.log(\"val_loss\", self.avg_valid_loss, on_step=False, on_epoch=True, prog_bar=False, logger=False)\n",
    "        self.log(\"val_acc\", self.valid_acc, on_step=False, on_epoch=True, prog_bar=False, logger=False)\n",
    "        \n",
    "          \n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.avg_train_loss = torch.stack([x['loss'] for x in outputs]).mean().item()\n",
    "        self.train_acc = (self.train_accm.compute() * 100).item()\n",
    "        self.train_accm.reset()\n",
    "        self.log(\"train_acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=False, logger=False)\n",
    "        self.log(\"train_loss\", self.avg_train_loss, on_step=False, on_epoch=True, prog_bar=False, logger=False)\n",
    "        self.log(\"epoch_num\", int(self.current_epoch+1), on_step=False, on_epoch=True, prog_bar=False, logger=False)\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.end_time = time.time()\n",
    "        self.epoch_mins, self.epoch_secs = self.epoch_time(self.start_time, self.end_time)\n",
    "        time_int = f'{self.epoch_mins}m {self.epoch_secs}s'\n",
    "    \n",
    "        metrics = {'epoch': self.current_epoch+1, 'Train Acc': self.train_acc, 'Train Loss': self.avg_train_loss,  'Valid Acc': self.valid_acc, 'Valid Loss': self.avg_valid_loss}\n",
    "        if self.table_context is None:\n",
    "          self.table_context = tp.TableContext(headers=['epoch', 'Train Acc', 'Train Loss', 'Valid Acc', 'Valid Loss', 'Time'])\n",
    "          self.table_context.__enter__()\n",
    "        self.table_context([self.current_epoch+1, self.train_acc, self.avg_train_loss, self.valid_acc, self.avg_valid_loss, time_int])\n",
    "        self.logger.log_metrics(metrics)\n",
    "\n",
    "        if self.current_epoch == self.trainer.max_epochs - 1:\n",
    "          self.table_context.__exit__()\n",
    "\n",
    "\n",
    "    def epoch_time(self, start_time, end_time):\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_mins = int(elapsed_time / 60)\n",
    "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "        return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee6ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "946f78c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training\n",
      "From base model: tensor([-0.0006, -0.0033])\n",
      "From PTL Module: tensor([-0.0006, -0.0033])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Before training')\n",
    "print(f'From base model: {base_model.state_dict()[\"fc2.bias\"]}')\n",
    "print(f'From PTL Module: {model.state_dict()[\"model.fc2.bias\"]}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f21ef3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='train_acc',\n",
    "    dirpath='./ckpt',\n",
    "    filename='model-{epoch_num:.0f}-{val_loss:.2f}',\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ec4ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | model      | CNN              | 2.2 M \n",
      "1 | loss_fn    | CrossEntropyLoss | 0     \n",
      "2 | train_accm | Accuracy         | 0     \n",
      "3 | valid_accm | Accuracy         | 0     \n",
      "------------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.981     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b875cb1f88cb4afbbd854e4b22dece81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff64e18e384b4b24b5267b1b5196f3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╭─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────╮\n",
      "│       epoch │   Train Acc │  Train Loss │   Valid Acc │  Valid Loss │        Time │\n",
      "├─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┤\n",
      "│           1 │        55.4 │      0.6837 │      59.625 │     0.67976 │      0m 10s │\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092488b2f9b04b46aa0d2baa5bd3931a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "│           2 │        64.4 │     0.65185 │        57.5 │     0.67269 │      0m 10s │\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b88f877b35348c1959e2e8c8ab6bcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "│           3 │        70.4 │     0.58671 │       59.25 │     0.68084 │      0m 11s │\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6d079154fb409285dff6d896905592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "│           4 │        75.1 │     0.53537 │      59.875 │     0.71231 │      0m 11s │\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e309655be2544439ab1c0b492dac6177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "│           5 │        79.9 │     0.43738 │      58.625 │     0.78774 │      0m 11s │\n",
      "╰─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────╯\n"
     ]
    }
   ],
   "source": [
    "csvlogger = CSVLogger('csv_logs', name='E1', version=0)\n",
    "trainer = pl.Trainer(max_epochs=5, num_sanity_val_steps=0, logger=csvlogger, gpus=0, callbacks=[checkpoint_callback], log_every_n_steps=1)\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bea97fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training\n",
      "From base model: tensor([ 0.0071, -0.0110])\n",
      "From PTL Module: tensor([ 0.0071, -0.0110])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('After training')\n",
    "print(f'From base model: {base_model.state_dict()[\"fc2.bias\"]}')\n",
    "print(f'From PTL Module: {model.state_dict()[\"model.fc2.bias\"]}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f0530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
